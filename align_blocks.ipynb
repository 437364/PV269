{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21b19281",
   "metadata": {},
   "source": [
    "Alignment approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "572f250a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyranges\n",
    "from collections import namedtuple\n",
    "from Bio import Align\n",
    "from Bio.Align import substitution_matrices\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "04594885",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_maternal=\"data/shared_contigs_maternal_coordinates.tsv\"\n",
    "path_paternal=\"data/shared_contigs_paternal_coordinates.tsv\"\n",
    "\n",
    "path_PAN028_index = \"data/assembly.v1.0.PAN028.diploid-002.fa.fai\"\n",
    "\n",
    "path_grandmother_genome = \"data/assembly.v1.0.PAN010.diploid-006.fa\"\n",
    "path_grandfather_genome = \"data/assembly.v1.0.PAN011.diploid-005.fa\"\n",
    "path_mother_genome = \"data/assembly.v1.0.PAN027.diploid-003.fa\"\n",
    "path_proband_genome = \"data/assembly.v1.0.PAN028.diploid-002.fa\"\n",
    "\n",
    "path_grandmother_RM = \"data/assembly.v1.0.PAN010.diploid.RM.bed\"\n",
    "path_grandfather_RM = \"data/assembly.v1.0.PAN011.diploid.RM.bed\"\n",
    "path_mother_RM = \"data/assembly.v1.0.PAN027.diploid.RM.bed\"\n",
    "path_proband_RM = \"data/assembly.v1.0.PAN028.diploid.RM.bed\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d45c8542",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_maternal = pd.read_csv(path_maternal, sep=\"\\t\", header=None, names=[\"Contig\", \"Grandparent\", \"Mother\", \"Proband\"])\n",
    "\n",
    "# Load repeat annotations as PyRanges objects\n",
    "rm_grandfather = pyranges.readers.read_bed(path_grandfather_RM)\n",
    "rm_grandmother = pyranges.readers.read_bed(path_grandmother_RM)\n",
    "rm_mother = pyranges.readers.read_bed(path_mother_RM)\n",
    "rm_proband = pyranges.readers.read_bed(path_proband_RM)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b031149c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_info(info): # PAN010.chr1.haplotype1:142532907-142550224\n",
    "    if pd.isna(info):\n",
    "        return pd.Series([None, None, None])\n",
    "    else:\n",
    "        info = info.split(\":\")\n",
    "        chr = info[0]\n",
    "        positions = info[1].split(\"-\")\n",
    "        start = int(positions[0])\n",
    "        end = int(positions[1])\n",
    "        return pd.Series([chr, start, end])\n",
    "def preprocess_rm(rm_df):\n",
    "    \"\"\"\n",
    "    Get rid of simple repeats\n",
    "    \"\"\"\n",
    "    rm_filt = rm_df[rm_df[\"ThickEnd\"] != \"unknown\"]\n",
    "\n",
    "\n",
    "    return rm_filt\n",
    "\n",
    "def extract_repeat_annotations(info, rm_bed):\n",
    "    if pd.isna(info):\n",
    "        return None\n",
    "    else:\n",
    "        chr, start, end = split_info(info)\n",
    "        rm_filtered = rm_bed[chr, start:end]\n",
    "        rm_df = rm_filtered.df.sort_values(by=\"Start\")\n",
    "        rm_preprocessed = preprocess_rm(rm_df)\n",
    "        rm_list = rm_preprocessed[[\"Chromosome\", \"Start\", \"End\", \"Name\", \"Score\", \"Strand\", \n",
    "                                   \"ThickStart\", \"ThickEnd\", \"ItemRGB\", \"BlockCount\"]].values.tolist()\n",
    "        \n",
    "        return rm_list\n",
    "\n",
    "def repeat_to_token(r):\n",
    "    RepeatToken = namedtuple(\"RepeatToken\", [\"name\", \"length\", \"strand\", \"type\", \"family\"])\n",
    "    return RepeatToken(r[3], r[4], r[5], r[6], r[7])\n",
    "\n",
    "def match_score(token1, token2, match_tolerance=0.1):\n",
    "    name1, len1, strand1, type1, family1 = token1\n",
    "    name2, len2, strand2, type2, family2 = token2\n",
    "\n",
    "    score = 0\n",
    "    if type1 == type2:\n",
    "        score += 1\n",
    "    if family1 == family2:\n",
    "        score += 1\n",
    "    if strand1 == strand2:\n",
    "        score += 1\n",
    "    else:\n",
    "        score -= 1\n",
    "    if name1 == name2:\n",
    "        score += 2\n",
    "    if abs(len1 - len2) <= match_tolerance * max(len1, len2):\n",
    "        score += 1\n",
    "\n",
    "    return score\n",
    "\n",
    "def align_repeat_lists(proband, grandparent, gap_penalty=-2, match_tolerance=0.1):\n",
    "    # Convert repeat annotations to tokens\n",
    "    tokens_p = [repeat_to_token(r) for r in proband]\n",
    "    tokens_g = [repeat_to_token(r) for r in grandparent]\n",
    "\n",
    "    m = len(tokens_p)\n",
    "    n = len(tokens_g)\n",
    "\n",
    "    # Initialize scoring matrix\n",
    "    M = np.zeros((m + 1, n + 1), dtype=int)\n",
    "\n",
    "    # Fill the first row and column with gap penalties\n",
    "    for i in range(1, m + 1):\n",
    "        M[i][0] = M[i - 1][0] + gap_penalty\n",
    "    for j in range(1, n + 1):\n",
    "        M[0][j] = M[0][j - 1] + gap_penalty\n",
    "\n",
    "    # Fill in the matrix\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            match = M[i - 1][j - 1] + match_score(tokens_p[i - 1], tokens_g[j - 1], match_tolerance)\n",
    "            delete = M[i - 1][j] + gap_penalty\n",
    "            insert = M[i][j - 1] + gap_penalty\n",
    "            M[i][j] = max(match, delete, insert)\n",
    "\n",
    "    # Traceback\n",
    "    aligned_proband = []\n",
    "    aligned_grandparent = []\n",
    "\n",
    "    i, j = m, n\n",
    "    while i > 0 and j > 0:\n",
    "        current_score = M[i][j]\n",
    "        diag = M[i - 1][j - 1]\n",
    "        up = M[i - 1][j]\n",
    "        left = M[i][j - 1]\n",
    "\n",
    "        if current_score == diag + match_score(tokens_p[i - 1], tokens_g[j - 1], match_tolerance):\n",
    "            aligned_proband.insert(0, proband[i - 1])\n",
    "            aligned_grandparent.insert(0, grandparent[j - 1])\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif current_score == up + gap_penalty:\n",
    "            aligned_proband.insert(0, proband[i - 1])\n",
    "            aligned_grandparent.insert(0, None)  # gap in grandparent = insertion\n",
    "            i -= 1\n",
    "        else:\n",
    "            aligned_proband.insert(0, None)  # gap in proband = deletion\n",
    "            aligned_grandparent.insert(0, grandparent[j - 1])\n",
    "            j -= 1\n",
    "\n",
    "    # Add any remaining elements (at edges)\n",
    "    while i > 0:\n",
    "        aligned_proband.insert(0, proband[i - 1])\n",
    "        aligned_grandparent.insert(0, None)\n",
    "        i -= 1\n",
    "    while j > 0:\n",
    "        aligned_proband.insert(0, None)\n",
    "        aligned_grandparent.insert(0, grandparent[j - 1])\n",
    "        j -= 1\n",
    "\n",
    "    return aligned_proband, aligned_grandparent, M\n",
    "\n",
    "def format_alignment_to_table(alignment):\n",
    "    aligned_grandparent = alignment[0]\n",
    "    aligned_proband = alignment[1]\n",
    "\n",
    "    table = []\n",
    "    insertions = []\n",
    "    for i, (p, g) in enumerate(zip(aligned_proband, aligned_grandparent)):\n",
    "        row = {\n",
    "            \"Proband\": p[3] if p else \"-\",\n",
    "            \"Grandparent\": g[3] if g else \"-\",\n",
    "            \"Type\": p[6] if p else g[6] if g else \"-\",\n",
    "            \"Family\": p[7] if p else g[7] if g else \"-\",\n",
    "            \"Status\": \"Match\" if p and g else \"Insertion\" if p else \"Deletion\"\n",
    "        }\n",
    "        table.append(row)\n",
    "        if p and not g:\n",
    "            ancestor_chromosome = aligned_grandparent[i-1][0] if i > 0 and aligned_grandparent[i - 1] else None\n",
    "            ancestor_start = aligned_grandparent[i - 1][2] if i > 0 and aligned_grandparent[i - 1] else None\n",
    "            ancestor_end = aligned_grandparent[i + 1][1] if i < len(aligned_grandparent) - 1 and aligned_grandparent[i + 1] else None\n",
    "            p.extend([ancestor_chromosome, ancestor_start, ancestor_end])\n",
    "            insertions.append(p)\n",
    "    \n",
    "    cols = [\"Chromosome\", \"Start\", \"End\", \"Name\", \"Length\", \"Strand\", \"Type\", \"Family\", \n",
    "            \"Score\", \"Index\", \"AncestorChromosome\", \"AncestorStart\", \"AncestorEnd\"]\n",
    "    insertions_df = pd.DataFrame(insertions, columns=cols)\n",
    "    return pd.DataFrame(table), insertions_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c24e182",
   "metadata": {},
   "source": [
    "# Single-thread "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173847b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_insertions_df = pd.DataFrame()\n",
    "alignment_dict = {}\n",
    "for row in df_maternal.itertuples(index=False):\n",
    "    contig, grandparent_info, mother_info, proband_info = row\n",
    "    grandparent_chr, grandparent_start, grandparent_end = split_info(grandparent_info)\n",
    "    mother_chr, mother_start, mother_end = split_info(mother_info)\n",
    "    proband_chr, proband_start, proband_end = split_info(proband_info)\n",
    "\n",
    "    grandparent_repeats = extract_repeat_annotations(grandparent_info, rm_grandmother)\n",
    "    mother_repeats = extract_repeat_annotations(mother_info, rm_mother)\n",
    "    proband_repeats = extract_repeat_annotations(proband_info, rm_proband) if not pd.isna(proband_info) else None\n",
    "    \n",
    "    if len(grandparent_repeats) > 2000:\n",
    "        n_chunks = len(grandparent_repeats) // 2000 + 1\n",
    "        chunk_size = len(grandparent_repeats) // n_chunks\n",
    "        for chunk in range(n_chunks):\n",
    "            start_id_descendant = max(1, chunk_size * chunk)\n",
    "            end_id_descendant = min(len(mother_repeats), chunk_size * (chunk + 1))\n",
    "            mother_repeats_chunk = mother_repeats[start_id_descendant: end_id_descendant]\n",
    "            grandparent_repeats_chunk = grandparent_repeats[max(1, start_id_descendant-20): min(len(grandparent_repeats), end_id_descendant+20)]\n",
    "            alignment = align_repeat_lists(grandparent_repeats_chunk, mother_repeats_chunk)\n",
    "            df, insertions = format_alignment_to_table(alignment)\n",
    "            insertions[\"Contig\"] = contig\n",
    "            all_insertions_df = pd.concat([all_insertions_df, insertions], ignore_index=True)\n",
    "            alignment_dict[f\"{contig}_{chunk}\"] = df \n",
    "    else:               \n",
    "        alignment = align_repeat_lists(grandparent_repeats, mother_repeats)\n",
    "        df, insertions = format_alignment_to_table(alignment)\n",
    "        insertions[\"Contig\"] = contig\n",
    "        all_insertions_df = pd.concat([all_insertions_df, insertions], ignore_index=True)\n",
    "        alignment_dict[contig] = df\n",
    "all_insertions_df.to_csv(\"data/insertions_grandmother_mother_single_thread.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3fe010",
   "metadata": {},
   "source": [
    "# Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34858ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def process_row(row):\n",
    "    contig, grandparent_info, mother_info, proband_info = row\n",
    "\n",
    "    grandparent_repeats = extract_repeat_annotations(grandparent_info, rm_grandmother)\n",
    "    mother_repeats = extract_repeat_annotations(mother_info, rm_mother)\n",
    "    proband_repeats = extract_repeat_annotations(proband_info, rm_proband) if pd.notna(proband_info) else None\n",
    "\n",
    "    result = []\n",
    "    local_alignment_dict = {}\n",
    "\n",
    "    if len(grandparent_repeats) > 2000:\n",
    "        n_chunks = len(grandparent_repeats) // 2000 + 1\n",
    "        chunk_size = len(grandparent_repeats) // n_chunks\n",
    "        for chunk in range(n_chunks):\n",
    "            start = max(1, chunk_size * chunk)\n",
    "            end = min(len(mother_repeats), chunk_size * (chunk + 1))\n",
    "            mother_chunk = mother_repeats[start:end]\n",
    "            grandparent_chunk = grandparent_repeats[max(1, start - 20):min(len(grandparent_repeats), end + 20)]\n",
    "            alignment = align_repeat_lists(grandparent_chunk, mother_chunk)\n",
    "            df, insertions = format_alignment_to_table(alignment)\n",
    "            insertions[\"Contig\"] = contig\n",
    "            result.append(insertions)\n",
    "            local_alignment_dict[f\"{contig}_{chunk}\"] = df\n",
    "    else:\n",
    "        alignment = align_repeat_lists(grandparent_repeats, mother_repeats)\n",
    "        df, insertions = format_alignment_to_table(alignment)\n",
    "        insertions[\"Contig\"] = contig\n",
    "        result.append(insertions)\n",
    "        local_alignment_dict[contig] = df\n",
    "\n",
    "    return pd.concat(result, ignore_index=True), local_alignment_dict\n",
    "\n",
    "# Parallel execution\n",
    "if __name__ == \"__main__\":\n",
    "    all_insertions_df = pd.DataFrame()\n",
    "    alignment_dict = {}\n",
    "\n",
    "    with Pool(cpu_count()) as pool:\n",
    "        results = list(tqdm(pool.imap(process_row, df_maternal.itertuples(index=False, name=None)), total=len(df_maternal)))\n",
    "\n",
    "    # Combine results\n",
    "    all_insertions_df = pd.concat([res[0] for res in results], ignore_index=True)\n",
    "    for res in results:\n",
    "        alignment_dict.update(res[1])\n",
    "\n",
    "    # Save output\n",
    "    all_insertions_df.to_csv(\"data/insertions_grandmother_mother.tsv\", sep=\"\\t\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "te_pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
